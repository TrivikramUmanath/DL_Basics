{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#First tut"
      ],
      "metadata": {
        "id": "JBW0PfZInM1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "vluEH8VO1UEd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.empty(2,3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f60XUL7N1eL-",
        "outputId": "2f8525b3-795c-4c79-e060-2775841023e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.7131e+29,  4.5377e-41, -8.9896e+29],\n",
              "        [ 4.5377e-41, -8.9897e+29,  4.5377e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UbJH64W4ohF",
        "outputId": "2da3fd37-3616-4667-9871-c4c0b7c0b225"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2598, 0.6133],\n",
            "        [0.5480, 0.2610]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.zeros(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW1DrB7B4o9_",
        "outputId": "14f7bd83-18a3-4a43-fa49-362bf059a7f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7aRD8nDhsTS",
        "outputId": "8734519e-d2ec-4c95-e8f4-aaaa8ce182bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(2,2,dtype=torch.float16)\n",
        "print(x.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58WBu8Oyhta5",
        "outputId": "a7f03dcc-abb4-4da0-a46e-f62e2e38d3e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([2.5,0.1])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1axu6Z9hzYd",
        "outputId": "68383076-70d3-46c2-e96c-48d455005041"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(2,2)\n",
        "y=torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z=x*y\n",
        "z=torch.add(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7iyknJah44Y",
        "outputId": "ac293c6f-56e4-43ab-9713-aa8d9827a55b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8041, 0.7547],\n",
            "        [0.0627, 0.2813]])\n",
            "tensor([[0.7922, 0.0489],\n",
            "        [0.8227, 0.3605]])\n",
            "tensor([[1.5963, 0.8036],\n",
            "        [0.8854, 0.6418]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.add_(x)\n",
        "print(y)#inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRqPzfFtiBhN",
        "outputId": "dd8db566-01ed-40a4-b36f-bfb82984e84d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.5963, 0.8036],\n",
            "        [0.8854, 0.6418]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=x-y\n",
        "z=torch.sub(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YazbUU9tiIW4",
        "outputId": "2774caf2-de65-46c0-df8d-e392b861e7e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7922, -0.0489],\n",
            "        [-0.8227, -0.3605]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=x-y\n",
        "z=torch.mul(x,y)#elementwise multiplication\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MusyYyJ7iSBg",
        "outputId": "47835dd4-6b7f-4aed-8b5d-085ecdc2bc22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2836, 0.6064],\n",
            "        [0.0555, 0.1805]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=torch.div(x,y)#elementwise\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUI-6dwkidl9",
        "outputId": "ea1fc24b-0afa-4326-ac66-eeeae9940d20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5037, 0.9392],\n",
            "        [0.0708, 0.4383]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:,0])\n",
        "print(x[1,1])\n",
        "print(x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zkrDsH2igJF",
        "outputId": "9daa0c12-9a57-48c4-e651-7a941a6a5e0c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3757, 0.6567, 0.5530],\n",
            "        [0.9452, 0.1693, 0.6243],\n",
            "        [0.2695, 0.1435, 0.4435],\n",
            "        [0.7510, 0.2189, 0.0314],\n",
            "        [0.8247, 0.4564, 0.6685]])\n",
            "tensor([0.3757, 0.9452, 0.2695, 0.7510, 0.8247])\n",
            "tensor(0.1693)\n",
            "0.1692989468574524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(4,4)\n",
        "print(x)\n",
        "y=x.view(16)\n",
        "print(y)\n",
        "y=x.view(-1,8)#-1 automatic\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfhpEmWi5mn",
        "outputId": "5d801615-6b41-4ca5-ea8d-33cadd09742f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1906, 0.2744, 0.8242, 0.9165],\n",
            "        [0.3902, 0.5975, 0.9544, 0.4461],\n",
            "        [0.2894, 0.7043, 0.0571, 0.6582],\n",
            "        [0.3248, 0.9508, 0.8135, 0.2023]])\n",
            "tensor([0.1906, 0.2744, 0.8242, 0.9165, 0.3902, 0.5975, 0.9544, 0.4461, 0.2894,\n",
            "        0.7043, 0.0571, 0.6582, 0.3248, 0.9508, 0.8135, 0.2023])\n",
            "tensor([[0.1906, 0.2744, 0.8242, 0.9165, 0.3902, 0.5975, 0.9544, 0.4461],\n",
            "        [0.2894, 0.7043, 0.0571, 0.6582, 0.3248, 0.9508, 0.8135, 0.2023]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "pl21MXd5jO0Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.ones(5)\n",
        "print(a)\n",
        "b=a.numpy()\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h01CRtYVjaZK",
        "outputId": "c20aaecb-2dca-4ce4-d60a-c6789e4a2493"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL3mP9gdjf_M",
        "outputId": "04645ecf-9e81-41b1-d3d2-a1426f64f3e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.ones(5)\n",
        "print(a)\n",
        "b=torch.from_numpy(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTMrxRLUjnnw",
        "outputId": "78e11b1d-e71b-4752-ce88-e5cd7776b829"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a+=1\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c8XR_Mjv3b",
        "outputId": "be5d1389-2704-4b93-dfbd-85e3094b5090"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  x=torch.ones(5,device=device)\n",
        "  y=torch.ones(5)\n",
        "  y=y.to(device)\n",
        "  z=x+y\n",
        "  # print(z)\n",
        "  z=z.to(\"cpu\")\n",
        "  print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqEMgoZXj4oa",
        "outputId": "fabb5c63-2afd-453a-8826-665931ec367d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7VFJLg9kFpl",
        "outputId": "45c1ab63-7bd5-4f74-9b5b-34db683e3f89"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(5,requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgCzW5BekYyE",
        "outputId": "ddb89193-ede1-40cb-e99c-194a2da35306"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Tut"
      ],
      "metadata": {
        "id": "tby6AhBBnRCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.randn(3,requires_grad=True)\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVLHNgBQk2t-",
        "outputId": "6459792a-522b-4fbd-d833-3cd3a7544a13"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1014, 0.6859, 0.5666], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x+2\n",
        "print(y)\n",
        "z=y*y*2\n",
        "print(z)\n",
        "z=z.mean()\n",
        "print(z)\n",
        "z.backward() #dz/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtG2Gp_8na1q",
        "outputId": "e64613d5-0302-4b77-b013-02d5fc1a814b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1014, 2.6859, 2.5666], grad_fn=<AddBackward0>)\n",
            "tensor([ 8.8317, 14.4286, 13.1752], grad_fn=<MulBackward0>)\n",
            "tensor(12.1452, grad_fn=<MeanBackward0>)\n",
            "tensor([2.8019, 3.5813, 3.4222])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=y*y*2\n",
        "v=torch.tensor([0.1,1.0,0.01],dtype=torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZK5vsyQpprp",
        "outputId": "d9d035ca-4c3f-473a-8239-af7fdd576eb8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3.6424, 14.3250,  3.5248])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_T6-cpfngfC",
        "outputId": "a016dc94-6c64-401c-b6ff-95af13389a34"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1014, 0.6859, 0.5666])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhYedCo4qUX6",
        "outputId": "6c868697-0c42-4dcf-ac89-23b3395bcfdc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1014, 0.6859, 0.5666])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y=x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IExx1OlrsYb",
        "outputId": "e5e167fa-1276-485a-f757-0ff29d026163"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.1014, 2.6859, 2.5666])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights=torch.ones(4,requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output=(weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  # weights.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzpt8Z5ur0Bd",
        "outputId": "0e3ef488-d1fa-4254-d4c3-34228e67f4e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9oqmkV_4yOi_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation Theory"
      ],
      "metadata": {
        "id": "grBKb8vryTPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.tensor(1.0)\n",
        "y=torch.tensor(2.0)\n",
        "\n",
        "w=torch.tensor(1.0,requires_grad=True)\n",
        "\n",
        "y_hat=w*x\n",
        "loss=(y_hat-y)**2\n",
        "print(loss)\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "#backward pass above\n",
        "#update weights\n",
        "#next forward and backward pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmowH2j8scxU",
        "outputId": "21822936-3cb2-42f2-cd8b-4f6b230589ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradientg Descent with AutoGrad and Bakckprop"
      ],
      "metadata": {
        "id": "VUVNP4ss2PWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=np.array([1,2,3,4],dtype=np.float32)\n",
        "Y=np.array([2,4,6,8],dtype=np.float32)\n",
        "\n",
        "w=0.0\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w-=learning_rate*dw\n",
        "  if epoch%2 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkbXdwlQ30bR",
        "outputId": "0a188a19-130c-4eb4-cd17-99e28434dd33"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:0.0\n",
            "epoch 1: w=1.200, loss=30.00000000\n",
            "epoch 3: w=1.872, loss=0.76800019\n",
            "epoch 5: w=1.980, loss=0.01966083\n",
            "epoch 7: w=1.997, loss=0.00050332\n",
            "epoch 9: w=1.999, loss=0.00001288\n",
            "Predictions after training:9.998952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate*w.grad\n",
        "  w.grad.zero_()\n",
        "  if epoch%10 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqNxSMHW5UVu",
        "outputId": "81f04525-84b8-4264-b207-e957dde222fd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:tensor(0., grad_fn=<MulBackward0>)\n",
            "epoch 1: w=0.300, loss=30.00000000\n",
            "epoch 11: w=1.665, loss=1.16278565\n",
            "epoch 21: w=1.934, loss=0.04506890\n",
            "epoch 31: w=1.987, loss=0.00174685\n",
            "epoch 41: w=1.997, loss=0.00006770\n",
            "epoch 51: w=1.999, loss=0.00000262\n",
            "epoch 61: w=2.000, loss=0.00000010\n",
            "epoch 71: w=2.000, loss=0.00000000\n",
            "epoch 81: w=2.000, loss=0.00000000\n",
            "epoch 91: w=2.000, loss=0.00000000\n",
            "Predictions after training:tensor(10.0000, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Loss and Optimizer"
      ],
      "metadata": {
        "id": "tDyj1TFX6g_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD([w],lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhjgZqXy57gB",
        "outputId": "6993ab1c-993f-4c2d-fa97-d08e5a017688"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:tensor(0., grad_fn=<MulBackward0>)\n",
            "epoch 1: w=0.300, loss=30.00000000\n",
            "epoch 11: w=1.665, loss=1.16278565\n",
            "epoch 21: w=1.934, loss=0.04506890\n",
            "epoch 31: w=1.987, loss=0.00174685\n",
            "epoch 41: w=1.997, loss=0.00006770\n",
            "epoch 51: w=1.999, loss=0.00000262\n",
            "epoch 61: w=2.000, loss=0.00000010\n",
            "epoch 71: w=2.000, loss=0.00000000\n",
            "epoch 81: w=2.000, loss=0.00000000\n",
            "epoch 91: w=2.000, loss=0.00000000\n",
            "Predictions after training:tensor(10.0000, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "X_test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "print(n_samples,n_features)\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "#model=nn.Linear(input_size,output_size)\n",
        "model=nn.Linear(input_size,output_size)\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(model(X_test).item()))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=model(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(model(X_test).item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Mqzkkf74Vi",
        "outputId": "a750ce82-db4b-4943-dee1-33087e1fa0a0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Predictions before training:-3.7600951194763184\n",
            "epoch 1: w=-0.399, loss=55.33649445\n",
            "epoch 11: w=1.313, loss=1.61599970\n",
            "epoch 21: w=1.597, loss=0.21539468\n",
            "epoch 31: w=1.651, loss=0.16905421\n",
            "epoch 41: w=1.668, loss=0.15833963\n",
            "epoch 51: w=1.679, loss=0.14910085\n",
            "epoch 61: w=1.689, loss=0.14042176\n",
            "epoch 71: w=1.698, loss=0.13224842\n",
            "epoch 81: w=1.707, loss=0.12455101\n",
            "epoch 91: w=1.716, loss=0.11730137\n",
            "Predictions after training:9.430187225341797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "X_test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "print(n_samples,n_features)\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "#model=nn.Linear(input_size,output_size)\n",
        "# model=nn.Linear(input_size,output_size)\n",
        "\n",
        "\n",
        "# 1 Design model, input and output size, forward pass\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):  # Corrected: __init__ not _init_\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(model(X_test).item()))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=model(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(model(X_test).item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POlq_SYB9v45",
        "outputId": "fbaa9f3f-7e84-4ac2-eba3-8c7775651dc8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Predictions before training:-1.7090098857879639\n",
            "epoch 1: w=0.024, loss=41.44714737\n",
            "epoch 11: w=1.504, loss=1.13685203\n",
            "epoch 21: w=1.747, loss=0.09017318\n",
            "epoch 31: w=1.791, loss=0.05955669\n",
            "epoch 41: w=1.803, loss=0.05543382\n",
            "epoch 51: w=1.810, loss=0.05219028\n",
            "epoch 61: w=1.816, loss=0.04915214\n",
            "epoch 71: w=1.821, loss=0.04629121\n",
            "epoch 81: w=1.827, loss=0.04359683\n",
            "epoch 91: w=1.832, loss=0.04105924\n",
            "Predictions after training:9.662879943847656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression using Pytorch"
      ],
      "metadata": {
        "id": "zDYBi3UyASjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design (input size,output size,forward pass)\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training Loop\n",
        "    # -forward pass: compute predictions and loss\n",
        "    # -backward pass: gradients\n",
        "    # -update weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_numpy,y_numpy = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
        "X=torch.from_numpy(x_numpy.astype(np.float32))\n",
        "Y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "Y=Y.view(Y.shape[0],1)\n",
        "n_samples,n_features=X.shape\n",
        "#Model\n",
        "input_size=n_features\n",
        "output_size=1\n",
        "model=nn.Linear(input_size,output_size)\n",
        "criteria=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "#Training\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted=model(X)\n",
        "  loss=criteria(y_predicted,Y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={loss:.4f}')\n",
        "\n",
        " #plot\n",
        "predicted=model(X).detach().numpy()\n",
        "plt.plot(x_numpy,y_numpy,'ro')\n",
        "plt.plot(x_numpy,predicted,'b')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "kcpviQsD-9Ut",
        "outputId": "7686e449-c4ef-4c26-b4b6-ff1c62ca5ed9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w=1.367, loss=5745.7114\n",
            "epoch 11: w=13.310, loss=4253.5723\n",
            "epoch 21: w=23.484, loss=3175.5444\n",
            "epoch 31: w=32.154, loss=2395.7856\n",
            "epoch 41: w=39.542, loss=1831.1553\n",
            "epoch 51: w=45.841, loss=1421.8879\n",
            "epoch 61: w=51.211, loss=1124.9575\n",
            "epoch 71: w=55.791, loss=909.3428\n",
            "epoch 81: w=59.696, loss=752.6505\n",
            "epoch 91: w=63.028, loss=638.6953\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression using Pytorch"
      ],
      "metadata": {
        "id": "NeoPElSNDVlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design (input size,output size,forward pass)\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training Loop\n",
        "    # -forward pass: compute predictions and loss\n",
        "    # -backward pass: gradients\n",
        "    # -update weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bc=datasets.load_breast_cancer()\n",
        "X,y=bc.data,bc.target\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
        "y_train=y_train.view(y_train.shape[0],1)\n",
        "y_test=y_test.view(y_test.shape[0],1)\n",
        "\n",
        "#f=wx+b,sigmoid at the end\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear=nn.Linear(n_input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted=torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "#Model\n",
        "model=LogisticRegression(n_features)\n",
        "#Loss and Optimizer\n",
        "criteria=nn.BCELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "#Training\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted=model(X_train)\n",
        "  loss=criteria(y_predicted,y_train)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: loss={loss:.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted=model(X_test)\n",
        "  y_predicted_cls=y_predicted.round()\n",
        "  acc=y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy={acc:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npa8pXioC-1M",
        "outputId": "8020f3bf-1f5c-4c94-cd69-c98f765d70b0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: loss=0.4900\n",
            "epoch 20: loss=0.4249\n",
            "epoch 30: loss=0.3796\n",
            "epoch 40: loss=0.3459\n",
            "epoch 50: loss=0.3196\n",
            "epoch 60: loss=0.2984\n",
            "epoch 70: loss=0.2809\n",
            "epoch 80: loss=0.2661\n",
            "epoch 90: loss=0.2533\n",
            "epoch 100: loss=0.2423\n",
            "accuracy=0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset and DataLoader"
      ],
      "metadata": {
        "id": "n4E5gx46HX3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "epoch = 1 forward and backward pass of ALL training samples\n",
        "batch_size= number of training sample in one forward and backward pass\n",
        "number of iterations = number of passes,each pass using[batch_size] number of samples\n",
        "e.g 100 samples,batch_size=20 -->100/20=5 iterations for 1 epoch\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy= np.loadtxt('/content/WineQT.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x=torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]])\n",
        "    self.n_samples=xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "dataset = WineDataset()\n",
        "# first_data = dataset[0]\n",
        "# features,labels = first_data\n",
        "# print(features,labels)\n",
        "\n",
        "dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "datatiter=iter(dataloader)\n",
        "data=next(datatiter)\n",
        "features,labels=data\n",
        "print(features,labels)\n",
        "\n",
        "\n",
        "#training loop\n",
        "num_epochs=2\n",
        "total_samples=len(dataset)\n",
        "n_iterations=math.ceil(total_samples/4)\n",
        "print(total_samples,n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(inputs,labels) in enumerate(dataloader):\n",
        "     # forward and backward,update (placeholders for actual model logic)\n",
        "\n",
        "     # --- ADDED CONDITION HERE TO MATCH VIDEO'S PRINT FREQUENCY ---\n",
        "     if (i + 1) % 5 == 0: # Print every 5th step\n",
        "       print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs shape: {inputs.shape}')\n",
        "\n",
        "print(\"\\nTraining loop simulation complete.\")\n",
        "\n",
        "# torchvision.datasets.MNIST()\n",
        "#fashion=mnist,tifar,coco\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmXfMt-zGc-I",
        "outputId": "0655ece9-a8d8-47a6-b987-165880a5cb76"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.4000e-01, 5.2000e-01, 3.2000e+00, 9.4000e-02, 1.7000e+01, 5.3000e+01,\n",
            "         1.0014e+00, 3.0500e+00, 8.1000e-01, 9.5000e+00, 6.0000e+00, 2.9400e+02],\n",
            "        [6.9000e-01, 0.0000e+00, 1.6500e+00, 5.5000e-02, 7.0000e+00, 1.2000e+01,\n",
            "         9.9162e-01, 3.4700e+00, 5.3000e-01, 1.2900e+01, 6.0000e+00, 9.9900e+02],\n",
            "        [9.0000e-01, 0.0000e+00, 1.6000e+00, 5.2000e-02, 9.0000e+00, 1.7000e+01,\n",
            "         9.9467e-01, 3.5000e+00, 6.3000e-01, 1.0900e+01, 6.0000e+00, 1.4550e+03],\n",
            "        [4.3000e-01, 3.4000e-01, 2.5000e+00, 8.0000e-02, 2.6000e+01, 8.6000e+01,\n",
            "         9.9870e-01, 3.3800e+00, 6.2000e-01, 9.5000e+00, 6.0000e+00, 4.1000e+02]]) tensor([[13.3000],\n",
            "        [ 6.4000],\n",
            "        [ 6.5000],\n",
            "        [ 9.0000]])\n",
            "1143 286\n",
            "epoch 1/2, step 5/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 10/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 15/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 20/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 25/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 30/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 35/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 40/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 45/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 50/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 55/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 60/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 65/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 70/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 75/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 80/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 85/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 90/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 95/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 100/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 105/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 110/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 115/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 120/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 125/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 130/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 135/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 140/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 145/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 150/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 155/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 160/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 165/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 170/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 175/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 180/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 185/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 190/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 195/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 200/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 205/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 210/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 215/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 220/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 225/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 230/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 235/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 240/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 245/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 250/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 255/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 260/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 265/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 270/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 275/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 280/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 285/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 5/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 10/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 15/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 20/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 25/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 30/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 35/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 40/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 45/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 50/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 55/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 60/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 65/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 70/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 75/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 80/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 85/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 90/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 95/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 100/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 105/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 110/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 115/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 120/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 125/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 130/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 135/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 140/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 145/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 150/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 155/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 160/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 165/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 170/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 175/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 180/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 185/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 190/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 195/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 200/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 205/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 210/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 215/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 220/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 225/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 230/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 235/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 240/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 245/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 250/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 255/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 260/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 265/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 270/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 275/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 280/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 285/286, inputs shape: torch.Size([4, 12])\n",
            "\n",
            "Training loop simulation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataSet Transforms"
      ],
      "metadata": {
        "id": "ZJh9PDJ3QyVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "\n",
        "# # dataset=torchvision.datasets.MNIST(\n",
        "# #     root='./data',transform=torchvision.transforms.ToTensor()\n",
        "# # )\n",
        "\n",
        "# '''\n",
        "# Transforms can be applied to PIL images,tensors,ndarrays or custom data\n",
        "# during creation of the Dataset\n",
        "\n",
        "\n",
        "# On Images:CeterCrop,Grayscale,Pad,RandomAffine,RandomCrop,RandomHorizontalFlip\n",
        "# ,RandomRotation,Resize,Scale\n",
        "\n",
        "# On Tensors\n",
        "# LinearTransformation,Normalize,RandomErasing\n",
        "\n",
        "# Conversion\n",
        "# TopIImage: from tensor or ndarray\n",
        "# ToTensor: from numpy.ndarray or PILImage\n",
        "\n",
        "# Generic\n",
        "# Write own class\n",
        "\n",
        "# Compose Multiple Transform\n",
        "# composed=transform.Compose([Rescale[256],RandomCrop(224)])\n",
        "# torchvision.transform.ReScale(256)\n",
        "# torchvision.transform.ToTensor()\n",
        "# '''\n",
        "\n",
        "\n",
        "# '''\n",
        "# epoch = 1 forward and backward pass of ALL training samples\n",
        "# batch_size= number of training sample in one forward and backward pass\n",
        "# number of iterations = number of passes,each pass using[batch_size] number of samples\n",
        "# e.g 100 samples,batch_size=20 -->100/20=5 iterations for 1 epoch\n",
        "# '''\n",
        "\n",
        "# import torch\n",
        "# import torchvision\n",
        "# from torch.utils.data import Dataset,DataLoader\n",
        "# import numpy as np\n",
        "# import math\n",
        "\n",
        "# class WineDataset(Dataset):\n",
        "#   def __init__(self,transform=None):\n",
        "#     #data loading\n",
        "#     xy= np.loadtxt('/content/WineQT.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "#     self.x=torch.from_numpy(xy[:,1:])\n",
        "#     self.y=torch.from_numpy(xy[:,[0]])\n",
        "#     self.n_samples=xy.shape[0]\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "#     inputs = self.x[index]\n",
        "#     targets = self.y[index]\n",
        "\n",
        "#     sample = {'inputs': inputs, 'targets': targets}\n",
        "\n",
        "#     if self.transform:\n",
        "#       sample = self.transform(sample)\n",
        "\n",
        "#     return sample['inputs'], sample['targets']\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return self.n_samples\n",
        "\n",
        "\n",
        "# class ToTensor:\n",
        "#   def __call__(self,sample):\n",
        "#     inputs,targets=sample\n",
        "#     return torch.from_numpy(inputs),torch.from_numpy(targets)\n",
        "\n",
        "# class MulTransform:\n",
        "#   def __init__(self,factor):\n",
        "#     self.factor=factor\n",
        "\n",
        "#   def __call__(self,sample):\n",
        "#     inputs,targets=sample\n",
        "#     inputs*=self.factor\n",
        "#     return inputs,targets\n",
        "\n",
        "\n",
        "# dataset = WineDataset(transform=ToTensor())\n",
        "# first_data = dataset[0]\n",
        "# features,labels = first_data\n",
        "# print(type(features),type(labels))\n",
        "\n",
        "# composed=torchvision.transforms.Compose([ToTensor(),MulTransform(4)])\n",
        "# dataset = WineDataset(transform=composed)\n",
        "# first_data = dataset[0]\n",
        "# features,labels = first_data\n",
        "# print(type(features),type(labels))\n",
        "\n",
        "# #\n",
        "\n",
        "# # dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "# # datatiter=iter(dataloader)\n",
        "# # data=next(datatiter)\n",
        "# # features,labels=data\n",
        "# # print(features,labels)\n",
        "\n",
        "\n",
        "# # #training loop\n",
        "# # num_epochs=2\n",
        "# # total_samples=len(dataset)\n",
        "# # n_iterations=math.ceil(total_samples/4)\n",
        "# # print(total_samples,n_iterations)\n",
        "# # for epoch in range(num_epochs):\n",
        "# #   for i,(inputs,labels) in enumerate(dataloader):\n",
        "# #      # forward and backward,update (placeholders for actual model logic)\n",
        "\n",
        "# #      # --- ADDED CONDITION HERE TO MATCH VIDEO'S PRINT FREQUENCY ---\n",
        "# #      if (i + 1) % 5 == 0: # Print every 5th step\n",
        "# #        print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs shape: {inputs.shape}')\n",
        "\n",
        "# print(\"\\nTraining loop simulation complete.\")\n",
        "\n",
        "# # torchvision.datasets.MNIST()\n",
        "# #fashion=mnist,tifar,coco\n",
        "\n"
      ],
      "metadata": {
        "id": "rTcQZWAzLiOH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self,transform=None):\n",
        "        #data laoding\n",
        "        xy = np.loadtxt('/content/WineQT.csv',delimiter=',',dtype=np.float32,skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:,1:])\n",
        "        self.y = torch.from_numpy(xy[:,[0]])# n_samples,1\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #dataset[0]\n",
        "        sample = self.x[index], self.y[index]\n",
        "        if(self.transform):\n",
        "            sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        #lenght of the dataset\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "\n",
        "#training loop\n",
        "num_epochs    = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations  = math.ceil(total_samples / 4)\n",
        "print(total_samples,n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs,labels) in enumerate(dataloader):\n",
        "        #forward, backward, update\n",
        "        if(i + 1) % 5 == 0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs},step {i+1}/{n_iterations}, inputs {inputs.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vFB_UTYocSQ",
        "outputId": "8e84d442-27f1-497c-be89-18e8dfad16e1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1143 286\n",
            "epoch 1/2,step 5/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 10/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 15/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 20/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 25/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 30/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 35/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 40/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 45/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 50/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 55/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 60/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 65/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 70/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 75/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 80/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 85/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 90/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 95/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 100/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 105/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 110/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 115/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 120/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 125/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 130/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 135/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 140/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 145/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 150/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 155/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 160/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 165/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 170/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 175/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 180/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 185/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 190/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 195/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 200/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 205/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 210/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 215/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 220/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 225/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 230/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 235/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 240/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 245/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 250/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 255/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 260/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 265/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 270/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 275/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 280/286, inputs torch.Size([4, 12])\n",
            "epoch 1/2,step 285/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 5/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 10/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 15/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 20/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 25/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 30/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 35/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 40/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 45/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 50/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 55/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 60/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 65/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 70/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 75/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 80/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 85/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 90/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 95/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 100/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 105/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 110/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 115/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 120/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 125/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 130/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 135/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 140/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 145/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 150/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 155/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 160/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 165/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 170/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 175/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 180/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 185/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 190/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 195/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 200/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 205/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 210/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 215/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 220/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 225/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 230/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 235/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 240/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 245/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 250/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 255/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 260/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 265/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 270/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 275/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 280/286, inputs torch.Size([4, 12])\n",
            "epoch 2/2,step 285/286, inputs torch.Size([4, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZRdiYWlXNqT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax and Cross - Entropy"
      ],
      "metadata": {
        "id": "D37kLxNtYNgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "\n",
        "x=np.array([2.0,1.0,0.1])\n",
        "outputs=softmax(x)\n",
        "print('softmax numpy:',outputs)\n",
        "\n",
        "x=torch.tensor([2.0,1.0,0.1])\n",
        "outputs=torch.softmax(x,dim=0)\n",
        "print('softmax torch:',outputs)\n",
        "\n",
        "\n",
        "def cross_etropy(actual,predicted):\n",
        "  loss=-np.sum(actual*np.log(predicted))\n",
        "  return loss\n",
        "#y must be one hot encoded\n",
        "#if class 0: [1,0,0]\n",
        "#if class 1: [0,1,0]\n",
        "#if class 2: [0,0,1]\n",
        "#3 classes\n",
        "Y=np.array([1,0,0])\n",
        "\n",
        "#y_pred has probabilities\n",
        "Y_pred_good=np.array([0.7,0.2,0.1])\n",
        "Y_pred_bad=np.array([0.1,0.3,0.6])\n",
        "l1=cross_etropy(Y,Y_pred_good)\n",
        "l2=cross_etropy(Y,Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "#torch\n",
        "loss=nn.CrossEntropyLoss()\n",
        "#nn.crossentropy loss applies : nn.LogSoftmax + nn.NLLLoss(Negative Log Likelihood Loss)\n",
        "#No Softmax in last layer\n",
        "#Y has class labels, not One Hot!\n",
        "#Y Pred has raw scores(logits),no Softmax!\n",
        "#\n",
        "Y=torch.tensor([0])\n",
        "#size=n_samples*n_classes=1*3\n",
        "Y_pred_good=torch.tensor([[2.0,1.0,0.1]])\n",
        "Y_pred_bad=torch.tensor([[0.5,2.0,0.3]])\n",
        "\n",
        "l1 = loss(Y_pred_good,Y)\n",
        "l2 = loss(Y_pred_bad,Y)\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n",
        "_,predictions1=torch.max(Y_pred_good,1)\n",
        "_,predicitions2=torch.max(Y_pred_bad,1)\n",
        "print(predictions1)\n",
        "print(predicitions2)\n",
        "\n",
        "#3 samples\n",
        "Y=torch.tensor([2,0,1])\n",
        "#size=n_samples*n_classes=1*3\n",
        "Y_pred_good=torch.tensor([[0.1,1.0,2.1],[2.0,1.0,0.1],[0.1,3.0,0.1]])\n",
        "Y_pred_bad=torch.tensor([[2.1,1.0,0.1],[0.1,1.0,2.1],[0.1,3.0,0.1]])\n",
        "\n",
        "l1 = loss(Y_pred_good,Y)\n",
        "l2 = loss(Y_pred_bad,Y)\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n",
        "_,predictions1=torch.max(Y_pred_good,1)\n",
        "_,predicitions2=torch.max(Y_pred_bad,1)\n",
        "print(predictions1)\n",
        "print(predicitions2)\n"
      ],
      "metadata": {
        "id": "J2x6-flCHq6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576e2797-36a5-4192-967d-b716f0c0c3ef"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "0.4170299470424652\n",
            "1.840616226196289\n",
            "tensor([0])\n",
            "tensor([1])\n",
            "0.3018244206905365\n",
            "1.6241613626480103\n",
            "tensor([2, 0, 1])\n",
            "tensor([0, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet2,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    return out\n",
        "\n",
        "model=NeuralNet2(input_size=28*28,hidden_size=5,num_classes=3)\n",
        "criterion=nn.CrossEntropyLoss() #applies Softmax\n"
      ],
      "metadata": {
        "id": "JJiEAbeoq1Q7"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet2,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    y_pred=torch.sigmoid(out)\n",
        "    return y_pred\n",
        "\n",
        "model=NeuralNet2(input_size=28*28,hidden_size=5,num_classes=2)\n",
        "criterion=nn.BCELoss() #applies Softmax\n"
      ],
      "metadata": {
        "id": "QH0x935frjx3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Fuctions"
      ],
      "metadata": {
        "id": "VyA1SKv2rzVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step is very simple and not used in practise\n",
        "sigmoid is a popular choice and outputs prob  used in last layer of binary classifications\n",
        "tanh function hyperbolic tanget function outputs value from -1 to 1\n",
        "used in hidden layers a lot\n",
        "relu is max(0,x) is most popular for hidden if you don't know which activation to use in hidden layer just use relu\n",
        "leaky relu is also used to solve the vanishing gradient problem in hidden layers\n",
        "since in relu if x is less than 0 the value obtained is 0 which leads to gradient becoming 0 further on leading to these weights never being updated these neurons won't learn anything and hence dead so leaky relu is to counter that.\n",
        "softmax is most populat used for multi class setting"
      ],
      "metadata": {
        "id": "oqdx6ue3s5XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.Relu()\n",
        "    # nn.Sigmoid\n",
        "    # nn.Softmax\n",
        "    # nn.TanH\n",
        "    # nn.LeakyRelu\n",
        "    self.linear2=nn.Linear(hidden_size,1)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    out=self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "#option 2 use activation functions directly in forward pass\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1=nn.Linear(input_size,hidden_size)\n",
        "    self.linear2=nn.Linear(hidden_size,1)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=torch.relu(self.linear1(x))\n",
        "    out=torch.sigmoid(self.lineaer2(out))\n",
        "    # torch.softmax\n",
        "    # torch.tanh\n",
        "    #leaky relu in torch.functional module as F.leaky_relu()\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "rb87oBEaXm2n"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fully Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "SC2ClcBrvpr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST\n",
        "#DataLoader,Transforomation\n",
        "#Multilayer,Neural Net,activation function\n",
        "#Loss and Optimizer\n",
        "#Training Loop(batch training)\n",
        "#Model evaluation\n",
        "#GPU Support\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#device config\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper parameters\n",
        "input_size=784 # 28x28\n",
        "hidden_size=100\n",
        "num_classes=10\n",
        "num_epochs=2\n",
        "batch_size=100\n",
        "learning_rate=0.001\n",
        "\n",
        "#MNIST\n",
        "train_dataset=torchvision.datasets.MNIST(root='./data',train=True,\n",
        "        transform=transforms.ToTensor(),download=True)\n",
        "\n",
        "test_dataset=torchvision.datasets.MNIST(root='./data',train=False,\n",
        "        transform=transforms.ToTensor())\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,\n",
        "                              shuffle=False)\n",
        "\n",
        "examples=iter(train_loader)\n",
        "samples,labels=next(examples)\n",
        "print(samples.shape,labels.shape)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[i][0],cmap='gray')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "HCgZUtszvo3G",
        "outputId": "d428699b-8209-4e6e-f04a-0c83cf22f8ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGKCAYAAACsHiO8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALxdJREFUeJzt3Xt0VeWZx/HnBMnhlpxwkYQIGdKK95l0ZEjMQh3UKF4GQbAdu5yOt5YRExBw1FIRZhzaKN4QGmXsEtMZizApRhZ0iXUiBi8JDoHWIiWVVZSUkCBLcxIDuZC88wfLU+P7puyTc/Lus3e+n7X2H/lln32eDY/xYefd+wSUUkoAAAAsSXK7AAAAMLAwfAAAAKsYPgAAgFUMHwAAwCqGDwAAYBXDBwAAsIrhAwAAWMXwAQAArGL4AAAAVjF8AAAAq/pt+CgpKZGJEyfKkCFDJC8vT95///3+eisgruhdeBW9C68I9Mdnu2zcuFH++Z//WdauXSt5eXmyatUqKSsrk9raWhk7duxffG13d7fU19dLSkqKBAKBeJeGAUIpJS0tLZKZmSlJSc5nbHoXbqN34VVR9a7qB7m5uaqwsDDydVdXl8rMzFTFxcWnfW1dXZ0SETa2uGx1dXX0LpsnN3qXzaubk96N+69dOjo6pKamRgoKCiJZUlKSFBQUSFVVlbZ/e3u7NDc3RzbFh+wijlJSUhzvS+8ikdC78ConvRv34ePYsWPS1dUl6enpPfL09HRpaGjQ9i8uLpZQKBTZsrKy4l0SBrBoLiHTu0gk9C68yknvun63y5IlSyQcDke2uro6t0sCHKF34VX0Ltx2RrwPOGbMGBk0aJA0Njb2yBsbGyUjI0PbPxgMSjAYjHcZQNToXXgVvQuvifuVj+TkZJk8ebJUVFREsu7ubqmoqJD8/Px4vx0QN/QuvIrehedEtZzaoQ0bNqhgMKhKS0vVvn371Ny5c1VaWppqaGg47WvD4bDrK3XZ/LOFw2F6l82TG73L5tXNSe/2y/ChlFJr1qxRWVlZKjk5WeXm5qrq6mpHr+M/ArZ4btH+AKd32RJlo3fZvLo56d1+echYLJqbmyUUCrldBnwiHA5LamqqlfeidxFP9C68yknvun63CwAAGFgYPgAAgFUMHwAAwCqGDwAAYBXDBwAAsIrhAwAAWMXwAQAArGL4AAAAVjF8AAAAqxg+AACAVQwfAADAKoYPAABgFcMHAACwiuEDAABYxfABAACsYvgAAABWMXwAAACrznC7AAAAEs2MGTO0LCMjQ8uuvPJKLQuFQsZjXnvttY7eOxAIaNn+/fu17Pzzz3d0vETElQ8AAGAVwwcAALCK4QMAAFjF8AEAAKxiwSkAwNOysrK07O6779ay3Nxc4+unTp2qZcnJyVpmWghqsmfPHmP+7rvvatmkSZO0bPDgwVpmOkcv48oHAACwiuEDAABYxfABAACsYvgAAABWseDUJcOGDTPmf/u3f6tlN9xwg6NjmhZNDR8+3LjvkSNHtOx3v/udlq1fv17L9u7d66geAOir3hZYPvnkk1pmenJobz/7TN5++20tM/2M/OUvf6llFRUVWtba2mp8n66uLi0bOnSolj344INadv/992vZ+PHjje/zpz/9yZgnEq58AAAAqxg+AACAVQwfAADAKoYPAABgFcMHAACwKqCUUm4X8VXNzc0SCoXcLqPPTI/kNT3S95VXXjG+fsyYMX1+b9Ojf2P96z18+LCWPfHEE1r27LPPGl/f2dkZ0/vHKhwOS2pqqpX38nrvxmrIkCFaNm3aNC37zne+o2WTJ0/WsjPPPDMudX3VBx98oGX19fUxHfPYsWOOMhGRlStXOj7uQOrd7373u1r23HPPGfc1/ZkcPXpUy7Zv365lpjtlRER27dp1uhL7zQUXXKBlu3fv1jLTnTLR3NFjk5Pe5coHAACwiuEDAABYxfABAACsYvgAAABW8Xj1OLvuuuu0rLy83IVK4uOss87SsqefflrLTAv5RMyLvuBtOTk5xtz0KP7zzz9fy+rq6rTM9CjrQ4cOGd/n008/1TKni1PPPvtsLcvLyzPua1qA6XRRdzgcNh4zmgWnA4np76+3v/81a9Zo2auvvqplpj5x2ze+8Q0tM/3/YdCgQVq2devWfqnJLVz5AAAAVjF8AAAAq6IePnbs2CEzZsyQzMxMCQQC2uUupZQsW7ZMxo0bJ0OHDpWCggL56KOP4lUv0Gf0LryK3oXfRD18tLa2Sk5OjpSUlBi/v3LlSlm9erWsXbtWdu7cKcOHD5fp06dLW1tbzMUCsaB34VX0LvwmpiecBgIBKS8vl1mzZonIqek7MzNT7rvvPvnXf/1XETm18Co9PV1KS0vllltuOe0x3X7SXjQuueQSLTMtHkpPT3d8zA8//FDL3nvvPS174403tGzq1Kla1tsT8Ez7mhYHOvXTn/7UmC9YsKDPx4yH3p60N9B71ynTE3c3bdpk3Peyyy7TsubmZi279NJLtWzv3r19qC56wWBQy0xPJRYR+eEPf6hlpkWQpj+P9vZ24zFbWlpOV2IEvesNpif7XnjhhcZ9f/GLX2iZaRHqli1btGzOnDl9qM4d1p9wevDgQWloaJCCgoJIFgqFJC8vT6qqquL5VkBc0bvwKnoXXhTXW20bGhpERP+Xfnp6euR7X9fe3t7jXwmmfykB/Y3ehVfRu/Ai1+92KS4ullAoFNkmTJjgdkmAI/QuvIrehdviOnxkZGSIiEhjY2OPvLGxMfK9r1uyZImEw+HIZnoAEdDf6F14Fb0LL4rrr12ys7MlIyNDKioq5Fvf+paInLqct3PnTpk3b57xNcFg0LgIzAsWL16sZabFpZ9//rmj14qIlJWVadnx48cd1WP6WOjx48cb9zUtiHO64NS0qHbp0qWOXpuoBlrvOjV//nwtMy0sFRFZsWKFlpmehmv678EWU9/3tjj0oYce6u9y4oLedW7YsGHGfOTIkVpmGtxuvvlmLbvxxhu1rLefpSdPntQyry8u7auoh48vvvhCDhw4EPn64MGD8pvf/EZGjRolWVlZsnDhQlmxYoVMmjRJsrOz5eGHH5bMzMzIymzALfQuvIrehd9EPXzs2rVLrrjiisjXX/4L/rbbbpPS0lJ54IEHpLW1VebOnStNTU1y6aWXyrZt24y3IwE20bvwKnoXfhP18DFt2jTjByl9KRAIyCOPPCKPPPJITIUB8UbvwqvoXfiN63e7AACAgYXhAwAAWBXXu138qrc7Rr76O9gvmW5Zu/XWW7XsnXfecfxef//3f69l999/v5ZNmjRJy8466yzj+8TCdAcDDynyp6uvvlrLOjo6jPuanqbp5p0twNfdd999xvzf//3frbx/Z2enlq1fv97KeycarnwAAACrGD4AAIBVDB8AAMAqhg8AAGAVC04d6O1BPaNHj3aUrVu3TstaW1uNxxw1apSWOf3Qp0AgoGV/6dkAwOk89dRTWrZ8+XLjvv/zP/+jZRs2bNAy02PYP/nkkz5UB0TnoosucrzviRMn+vw+Z5xh/l/r0KFDtez555/Xsurqai07fPhwn+tJRFz5AAAAVjF8AAAAqxg+AACAVQwfAADAqoBKsBWJzc3NEgqF3C6jh7PPPtuY/+EPf7BcyV/WHwtOd+3apWWmJ67GsjirP4XDYUlNTbXyXonYu/2htwXYpsWp3/ve97Rs2LBhWvbQQw9p2ZNPPml8H9NTIv2I3rVn5syZWrZ161Yt6+rqcnS88847z5ib+tz0BOzf/e53WpaTk+PovROBk97lygcAALCK4QMAAFjF8AEAAKxi+AAAAFax4NSB3p5W98orr2jZP/zDP/R3OSJiXghaU1OjZf/yL/8S0/u88847Wnb55ZfHdEybWLTnrokTJ2qZ6YmOBQUFWrZkyRLjMR977LGY6/ICetd/xo0bp2Uffvihlpn+n2O68eHo0aPxKSzOWHAKAAASDsMHAACwiuEDAABYxfABAACsYsFpDExPejQtxty2bZuWrVu3znjMxsZGLTMtLv3Vr36lZVdccYWWvfbaa8b3cfrepoWApgVSiWqgL9rr7SPE9+7da7mSv+zIkSNa1traaty3tycO+81A792B4oEHHtCyRx99VMuWL1+uZf/xH//RLzXFigWnAAAg4TB8AAAAqxg+AACAVQwfAADAKoYPAABglfm54XCkra1Ny379619rWVKSnRlv2rRpWhYIBBy/fsGCBVrmpTtbBro5c+ZoWWZmpnFfN+92ufrqq7Vs7NixWrZlyxYb5QCu2rlzp6P9TB9V4GVc+QAAAFYxfAAAAKsYPgAAgFUMHwAAwCoWnPqIaSFfb0/P//TTT7Vsz549ca8J9vzsZz/TssLCQhcq+bPp06dr2S9/+Ust6+jo0LJnnnmmX2qCu7KysrTs5MmTWlZfX2+jHNddcMEFbpfgCq58AAAAqxg+AACAVQwfAADAKoYPAABgFQtOPWrUqFFaNnnyZC3rbcHpL37xCy07cOBA7IXBNe+//76WzZo1y7iv6Um8Tl111VXG3LRw7v7779eyoUOHallJSYmWbd++vQ/VIZHceOONWjZ//nwt+7d/+zct8+OC09GjR2vZwoULtayrq0vLNm7c2B8luYYrHwAAwCqGDwAAYFVUw0dxcbFMmTJFUlJSZOzYsTJr1iypra3tsU9bW5sUFhbK6NGjZcSIETJnzhxpbGyMa9FAtOhdeBW9Cz+KaviorKyUwsJCqa6uljfeeEM6OzvlmmuukdbW1sg+ixYtki1btkhZWZlUVlZKfX29zJ49O+6FA9Ggd+FV9C78KKB6W5HowKeffipjx46VyspKufzyyyUcDsuZZ54p69evl5tvvllERPbv3y/nn3++VFVVySWXXHLaYzY3N0soFOprSQOG6emPCxYs0LLPP//c+PqLL75Yyz7++OOY60o04XBYUlNTtdyPvfs3f/M3Wvb6668b901PT+/vckRE5OjRo1r29NNPa9l//ud/allTU1N/lOQZXuvdGTNmaNm9996rZXfccYeW1dXVxfTeiSYYDBpz08LqO++8U8sOHTqkZRMnToy5Llt6692vimnNRzgcFpE/33lRU1MjnZ2dUlBQENnnvPPOk6ysLKmqqorlrYC4onfhVfQu/KDPt9p2d3fLwoULZerUqXLRRReJiEhDQ4MkJydLWlpaj33T09OloaHBeJz29nZpb2+PfN3c3NzXkgBH6F14Fb0Lv+jzlY/CwkLZu3evbNiwIaYCiouLJRQKRbYJEybEdDzgdOhdeBW9C7/o0/BRVFQkW7dule3bt8v48eMjeUZGhnR0dGi/q21sbJSMjAzjsZYsWSLhcDiy+e13f0gs9C68it6Fn0T1axellMyfP1/Ky8vlrbfekuzs7B7fnzx5sgwePFgqKipkzpw5IiJSW1srhw4dkvz8fOMxg8Fgr4tz0DvTIiWTtrY2Y+7HxaV/yUDo3Q8++EDLelts+N3vflfLJk2a5Oh9envy5I4dO7TsnXfe0bITJ044eh+ckmi9a3pCrYjIqlWrtMz0NFwvDzqmPzPTfzdLly41vv473/mOln366ada9uXCYT+LavgoLCyU9evXy+bNmyUlJSXy+8RQKCRDhw6VUCgkd911lyxevFhGjRolqampMn/+fMnPz3e04hroL/QuvIrehR9FNXw899xzIiIybdq0HvmLL74ot99+u4icuo0uKSlJ5syZI+3t7TJ9+nR59tln41Is0Ff0LryK3oUfRf1rl9MZMmSIlJSUGO9nBtxC78Kr6F34EZ/tAgAArGL4AAAAVvX5IWOwx/RY3UGDBtkvBJ7zySefGPNHH33UciXwi8cee8yYHz9+XMs+++yz/i6nV6Y7U4YPH27c96u3Ln9p6tSpWnbllVdq2Zd3GDnx9Q8EFBG54YYbtOyPf/yj42N6FVc+AACAVQwfAADAKoYPAABgFcMHAACwigWnHnDjjTdq2ZAhQxy99oUXXoh3OQAGsNdee82Yz5s3T8uqqqq0zNbj1c866ywtu/DCC2M6ZkdHh5YdPnxYy8rKyoyvX7ZsmZZ98cUXMdXkVVz5AAAAVjF8AAAAqxg+AACAVQwfAADAKhacesDdd9/taL+TJ09q2VtvvRXnagAMZL0tOC0uLtays88+W8tmzpypZUOHDo2pJtOTfLu6urRsw4YNxtebFo0eOnRIy7Zs2aJlH3/8sYMK8XVc+QAAAFYxfAAAAKsYPgAAgFUMHwAAwCoWnHrAyJEjHe3X1tamZRUVFfEuBwA0pqd3Ar3hygcAALCK4QMAAFjF8AEAAKxi+AAAAFYxfAAAAKu428VH3nvvPbdLAADgtLjyAQAArGL4AAAAVjF8AAAAqxg+AACAVSw49YBx48a5XQIAAHHDlQ8AAGAVwwcAALCK4QMAAFiVcMOHUsrtEuAjNvuJ3kU80bvwKif9lHDDR0tLi9slwEds9hO9i3iid+FVTvopoBJs5O3u7pb6+npJSUmRlpYWmTBhgtTV1UlqaqrbpcWsubmZ87FEKSUtLS2SmZkpSUl2Zmx61zsS+Xzo3fhK5L/rvkjk84mmdxPuVtukpCQZP368iIgEAgEREUlNTU24P+RYcD52hEIhq+9H73pPop4PvRt/nI8dTns34X7tAgAA/I3hAwAAWJXQw0cwGJTly5dLMBh0u5S44HwGDr/92XA+A4ff/mw4n8SUcAtOAQCAvyX0lQ8AAOA/DB8AAMAqhg8AAGBVwg4fJSUlMnHiRBkyZIjk5eXJ+++/73ZJju3YsUNmzJghmZmZEggE5NVXX+3xfaWULFu2TMaNGydDhw6VgoIC+eijj9wp9jSKi4tlypQpkpKSImPHjpVZs2ZJbW1tj33a2tqksLBQRo8eLSNGjJA5c+ZIY2OjSxUnBq/2L71L79K7icHv/ZuQw8fGjRtl8eLFsnz5ctm9e7fk5OTI9OnT5ejRo26X5khra6vk5ORISUmJ8fsrV66U1atXy9q1a2Xnzp0yfPhwmT59urS1tVmu9PQqKyulsLBQqqur5Y033pDOzk655pprpLW1NbLPokWLZMuWLVJWViaVlZVSX18vs2fPdrFqd3m5f+ldepfeTQy+71+VgHJzc1VhYWHk666uLpWZmamKi4tdrKpvRESVl5dHvu7u7lYZGRnq8ccfj2RNTU0qGAyql19+2YUKo3P06FElIqqyslIpdar2wYMHq7Kyssg+v//975WIqKqqKrfKdJVf+pfeHXjo3cTlt/5NuCsfHR0dUlNTIwUFBZEsKSlJCgoKpKqqysXK4uPgwYPS0NDQ4/xCoZDk5eV54vzC4bCIiIwaNUpERGpqaqSzs7PH+Zx33nmSlZXlifOJNz/3L73rb/RuYvNb/ybc8HHs2DHp6uqS9PT0Hnl6ero0NDS4VFX8fHkOXjy/7u5uWbhwoUydOlUuuugiETl1PsnJyZKWltZjXy+cT3/wc//Su/5G7yYuP/Zvwn2wHBJXYWGh7N27V9555x23SwGiQu/Cy/zYvwl35WPMmDEyaNAgbcVuY2OjZGRkuFRV/Hx5Dl47v6KiItm6dats37498umXIqfOp6OjQ5qamnrsn+jn01/83L/0rr/Ru4nJr/2bcMNHcnKyTJ48WSoqKiJZd3e3VFRUSH5+vouVxUd2drZkZGT0OL/m5mbZuXNnQp6fUkqKioqkvLxc3nzzTcnOzu7x/cmTJ8vgwYN7nE9tba0cOnQoIc+nv/m5f+ldf6N3E4vv+9flBa9GGzZsUMFgUJWWlqp9+/apuXPnqrS0NNXQ0OB2aY60tLSoPXv2qD179igRUU899ZTas2eP+uSTT5RSSj366KMqLS1Nbd68WX3wwQdq5syZKjs7W504ccLlynXz5s1ToVBIvfXWW+rIkSOR7fjx45F97r77bpWVlaXefPNNtWvXLpWfn6/y8/NdrNpdXu5fepfepXcTg9/7NyGHD6WUWrNmjcrKylLJyckqNzdXVVdXu12SY9u3b1ciom233XabUurUbV8PP/ywSk9PV8FgUF111VWqtrbW3aJ7YToPEVEvvvhiZJ8TJ06oe+65R40cOVINGzZM3XTTTerIkSPuFZ0AvNq/9C69S+8mBr/3L59qCwAArEq4NR8AAMDfGD4AAIBVDB8AAMAqhg8AAGAVwwcAALCK4QMAAFjF8AEAAKxi+AAAAFYxfAAAAKsYPgAAgFUMHwAAwCqGDwAAYBXDBwAAsIrhAwAAWMXwAQAArGL4AAAAVjF8AAAAqxg+AACAVQwfAADAKoYPAABgFcMHAACwiuEDAABYxfABAACsYvgAAABWMXwAAACrGD4AAIBVDB8AAMAqhg8AAGAVwwcAALCK4QMAAFjF8AEAAKxi+AAAAFYxfAAAAKvO6K8Dl5SUyOOPPy4NDQ2Sk5Mja9askdzc3NO+rru7W+rr6yUlJUUCgUB/lQefU0pJS0uLZGZmSlJSdDM2vQs30bvwqqh6V/WDDRs2qOTkZLVu3Tr14Ycfqh/84AcqLS1NNTY2nva1dXV1SkTY2OKy1dXV0btsntzoXTavbk56t1+Gj9zcXFVYWBj5uqurS2VmZqri4uLTvrapqcn1Pzg2/2xNTU30LpsnN3qXzaubk96N+5qPjo4OqampkYKCgkiWlJQkBQUFUlVVpe3f3t4uzc3Nka2lpSXeJWEAi+YSMr2LRELvwquc9G7ch49jx45JV1eXpKen98jT09OloaFB27+4uFhCoVBkmzBhQrxLAhyhd+FV9C68xvW7XZYsWSLhcDiy1dXVuV0S4Ai9C6+id+G2uN/tMmbMGBk0aJA0Njb2yBsbGyUjI0PbPxgMSjAYjHcZQNToXXgVvQuvifuVj+TkZJk8ebJUVFREsu7ubqmoqJD8/Px4vx0QN/QuvIrehedEtZzaoQ0bNqhgMKhKS0vVvn371Ny5c1VaWppqaGg47WvD4bDrK3XZ/LOFw2F6l82TG73L5tXNSe/2y/ChlFJr1qxRWVlZKjk5WeXm5qrq6mpHr+M/ArZ4btH+AKd32RJlo3fZvLo56d2AUkpJAmlubpZQKOR2GfCJcDgsqampVt6L3kU80bvwKie96/rdLgAAYGBh+AAAAFYxfAAAAKsYPgAAgFUMHwAAwCqGDwAAYBXDBwAAsIrhAwAAWMXwAQAArGL4AAAAVjF8AAAAq85wuwAktjvuuEPL1q1bp2U333yz8fWbNm2Ke00AAG/jygcAALCK4QMAAFjF8AEAAKxi+AAAAFax4BQR48aN07Inn3xSy7q7u7XsnHPO6ZeaACBR3H777Vr2ox/9SMsmTZpkfL1SytH7VFdXa9n111+vZU1NTY6Ol4i48gEAAKxi+AAAAFYxfAAAAKsYPgAAgFUsOB2gUlJStGz9+vVaFgqFtGzLli1a9tRTT8WnMAxII0aM0LLBgwfHdMyWlhYtO3nyZEzHhD/ddtttWvbwww9rWVZWlpYNGjRIy0yL8qORl5enZQcOHNCya665xvj63bt3x/T+NnDlAwAAWMXwAQAArGL4AAAAVjF8AAAAq1hwOkCtXbtWyy6//HItq6+v17KlS5dqWXt7e3wKg69cccUVWlZQUKBl3//+97XszDPPjOm9/+///k/LSktLtey///u/ja//4osvYnp/uOvv/u7vtOznP/+5cd9zzz1XywKBgJYdO3ZMy0xPI3355ZeN75Odna1lK1asMO77dSNHjtSyBx980LjvP/7jPzo6ppu48gEAAKxi+AAAAFYxfAAAAKsYPgAAgFUMHwAAwCrudvGR4cOHa9k//dM/Gfe9+eabtcz0OOpnnnlGy/bu3duH6uAX06ZNM+amx1FfeOGFWjZ27Nh4l2Q0ZcoUR9n9999vfP38+fO1bNu2bVrW1dXVh+oQT5dccomWbdq0ScsyMjIcH3PdunVaFuvPw6Qk/d/7b7/9tpa99tprWjZs2DAte+WVVxy/d6LhygcAALCK4QMAAFjF8AEAAKxi+AAAAFax4NRHRo8erWU//elPjfuaFj4VFxdr2RNPPBF7YfCVp556yph/61vfslvIV3z44YdaVl5ermUzZszQspycHOMxt2zZomULFizQsmeffVbLuru7jcdE7M455xwtKysr0zLT4tLPPvvMeMx77rlHy7Zu3aplJ06ccFJir0x9MW7cOC1LTk7WstbWVi3bv39/TPW4iSsfAADAKoYPAABgFcMHAACwKurhY8eOHTJjxgzJzMyUQCAgr776ao/vK6Vk2bJlMm7cOBk6dKgUFBTIRx99FK96gT6jd+FV9C78JuoFp62trZKTkyN33nmnzJ49W/v+ypUrZfXq1fLzn/9csrOz5eGHH5bp06fLvn37ZMiQIXEpGiJnnKH/1T333HNaZlpYKiLS2dmpZS+99FLshSUwevcvM53j97//fS0zPbW0N+FwWMtMT3SsqqrSMtOC0d4cOnRIy44fP65lP/nJT7TsjjvuMB5z1apVWrZ69WotMy123b59u/GYfUXv/tmoUaO0LDMzU8va2tq0bPr06cZj7t69O/bCvqK3n7u33nqrlhUVFWmZ6ef77bffrmW//e1voy8uQUQ9fFx33XVy3XXXGb+nlJJVq1bJ0qVLZebMmSIi8l//9V+Snp4ur776qtxyyy2xVQvEgN6FV9G78Ju4rvk4ePCgNDQ0SEFBQSQLhUKSl5dn/JeNiEh7e7s0Nzf32ADb6F14Fb0LL4rr8NHQ0CAiIunp6T3y9PT0yPe+rri4WEKhUGSbMGFCPEsCHKF34VX0LrzI9btdlixZIuFwOLLV1dW5XRLgCL0Lr6J34ba4PuH0yyfKNTY29nhqW2NjY69PPwwGgxIMBuNZxoBw/fXXa9m1117r+PXz5s3TssOHD8dUk5f5tXdNT08UEcnOztaye++9V8u+/e1va1lNTY3xmGvWrNGy119/XcsaGxuNr7fBtAjRtFBbRGTWrFladvXVV2vZ2rVrtezcc8+Nvrg+8mvvxioQCGhZamqqlffubRHz888/3+dj7ty5s8+vTURxvfKRnZ0tGRkZUlFREcmam5tl586dkp+fH8+3AuKK3oVX0bvwoqivfHzxxRdy4MCByNcHDx6U3/zmNzJq1CjJysqShQsXyooVK2TSpEmRW74yMzON/4oAbKJ34VX0Lvwm6uFj165dcsUVV0S+Xrx4sYiI3HbbbVJaWioPPPCAtLa2yty5c6WpqUkuvfRS2bZtm+/uNYf30LvwKnoXfhP18DFt2jRRSvX6/UAgII888og88sgjMRUGxBu9C6+id+E3rt/tAgAABpa43u2C/nHxxRdrWWlpqaPXbt682Zhv3LgxlpKQgP7qr/5Ky/73f//XuO83v/lNLWttbdUy0x0sP/7xj43HPHr06OlK9BTT49VNd7tMmjTJQjWIlulunl//+tfGfXfs2KFlTzzxhJZt27ZNy0yPR3/66aedlCgiIu+//76WPfPMM1p28OBBx8f0Aq58AAAAqxg+AACAVQwfAADAKoYPAABgFQtOPcD0oKBQKOTotcuWLTPmx48fj6UkuCwrK0vLvvqEyy994xvfML7+j3/8o5aZFs6ZFtgNFKZHscN9u3fv1rKcnBwtW7p0qZaZPi5ARHo8Q+VLeXl5WtbU1KRlo0eP1rLeemfTpk1atmDBAi0bCJ8yzJUPAABgFcMHAACwiuEDAABYxfABAACsYsFpghk3bpyW3XXXXS5UgkR2yy23aJlpcWlvC9/uvvtuLevtaagDlWnBoclDDz3Uz5Xgqzo6OrRs7969WnbrrbdqWXFxsfGYpqeMDhs2zFFmcvjwYWN+++23O3r9QMCVDwAAYBXDBwAAsIrhAwAAWMXwAQAArGLBqUsGDRpkzJ9//nkty8jIcHTM6upqLdu/f390hcET7r33Xkf7vfDCC8acxaV/duaZZxrzBx98UMtMCwlNH72OxHTdddcZ895+HqP/cOUDAABYxfABAACsYvgAAABWMXwAAACrWHDqkp/85CfG/Prrr3f0+k8//VTL7rvvPi07efJkdIXBE0xPwkXfLFu2zJiHQiEtu+eee7Sss7Mz7jUhOmecof+vzLQo+8c//rHjYx4/ftxRNmbMGC3rbQHriBEjtOyLL75wXJOfcOUDAABYxfABAACsYvgAAABWMXwAAACrGD4AAIBV3O1iwdVXX61l8+fPd/z67u5uLZs5c6aW7dq1K7rCgAFm1qxZWnbnnXca933ppZe0rKysLN4lIQ5MP09Xrlzp+PXt7e1aZuqLnTt3atnrr7+uZeecc47xfcrLy7XM9P+HgYArHwAAwCqGDwAAYBXDBwAAsIrhAwAAWMWC0zgbPny4li1YsEDLgsGg42Nu2bJFy0wLnzBwtLa2apmp91JTU42vHzJkiJa1tbXFXphLBg8erGVFRUVatmLFCi3705/+ZDym6fV8XIH7zjrrLC3rbdGwU2lpaVrW0dHh6LV1dXVa1tuC06lTp0ZVl59x5QMAAFjF8AEAAKxi+AAAAFYxfAAAAKtYcBpnU6ZM0bJvfvObjl9/6NAhLfvZz34WU03wn1WrVmnZQw89pGXf+973jK8/duyYlj322GNadvTo0eiL62fnnnuulj3//PNadtlll2nZH/7wBy279tprje/T3Nzch+rQ3yZMmKBlF1xwgaPXmhYci4h0dnb2uZ6qqiotu+qqq4z7mm40WLp0qZb1VqefcOUDAABYxfABAACsYvgAAABWRTV8FBcXy5QpUyQlJUXGjh0rs2bNktra2h77tLW1SWFhoYwePVpGjBghc+bMkcbGxrgWDUSL3oVX0bvwo6gWnFZWVkphYaFMmTJFTp48KT/60Y/kmmuukX379kWerrho0SL51a9+JWVlZRIKhaSoqEhmz54t7777br+cgJvS09O17K677tIy0wK53p6UuGnTJi177bXX+lAdvspvvfv0009rmWnR3U033WR8/aJFi7TMtDi1srJSy5555hnjMY8fP27MncjLy9Oyb3/728Z9TYu6zzhD/1Fmqv2OO+7Qso8//thBhe7xW+/G6q//+q8d7ffee+9pmWmhtoiIUqrP9ZSXl2uZaRFpb0xP5x0Ioho+tm3b1uPr0tJSGTt2rNTU1Mjll18u4XBYXnjhBVm/fr1ceeWVIiLy4osvyvnnny/V1dVyySWXxK9yIAr0LryK3oUfxbTmIxwOi4jIqFGjRESkpqZGOjs7paCgILLPeeedJ1lZWcbbkURE2tvbpbm5uccG9Dd6F15F78IP+jx8dHd3y8KFC2Xq1Kly0UUXiYhIQ0ODJCcnax/Sk56eLg0NDcbjFBcXSygUimyme7iBeKJ34VX0Lvyiz8NHYWGh7N27VzZs2BBTAUuWLJFwOBzZTJ8QCMQTvQuvonfhF316wmlRUZFs3bpVduzYIePHj4/kGRkZ0tHRIU1NTT2m8MbGRsnIyDAeKxgMRvXx8omkq6tLy66//npHr21paTHma9eujakm/GV+6d3PPvtMy37wgx9oWX19vfH1N9xwg5ZNnDhRy+bMmeMoi1UgENCy3p46uWPHDi277777tOy3v/1t7IUlEL/0bqxuvfVWR/u99NJLWvb555/HuxwpKiqK+zEHgqiufCilpKioSMrLy+XNN9+U7OzsHt+fPHmyDB48WCoqKiJZbW2tHDp0SPLz8+NTMdAH9C68it6FH0V15aOwsFDWr18vmzdvlpSUlMjvE0OhkAwdOlRCoZDcddddsnjxYhk1apSkpqbK/PnzJT8/nxXXcBW9C6+id+FHUQ0fzz33nIiITJs2rUf+4osvyu233y4ip54/kJSUJHPmzJH29naZPn26PPvss3EpFugrehdeRe/Cj6IaPpw8iGXIkCFSUlIiJSUlfS4KiDd6F15F78KP+GwXAABgVZ/udsEpprsLvn6vfW9Mj7IWETlw4EAsJWEAM90BM3/+fOO+P/zhD7XM9Njye++9V8tSUlL6UN2fbd68WctMd7aYHlstInxmyQBXWlqqZZdddpmW3XnnnVr29ttvO36fJUuWaJnp53tubq7jYx4+fFjL1q9f7/j1fsKVDwAAYBXDBwAAsIrhAwAAWMXwAQAArAooJ/dxWdTc3CyhUMjtMhy5+OKLtcy0oKmmpkbLvvoJlF/V0dERe2GICIfDkpqaauW9vNS7SHz0rpnpwWnvvvuuC5WccvLkSS37+OOPjfvOnDlTy/bv3x/vklznpHe58gEAAKxi+AAAAFYxfAAAAKsYPgAAgFU84TQGu3fv1rLhw4e7UAkADAyHDh3SsgcffFDLZs+erWV5eXlxr+exxx7TsmXLlsX9ffyGKx8AAMAqhg8AAGAVwwcAALCK4QMAAFjFE07hazwlEl5F78KreMIpAABIOAwfAADAKoYPAABgFcMHAACwiuEDAABYxfABAACsYvgAAABWMXwAAACrGD4AAIBVDB8AAMAqhg8AAGAVwwcAALCK4QMAAFjF8AEAAKxKuOFDKeV2CfARm/1E7yKe6F14lZN+Srjho6Wlxe0S4CM2+4neRTzRu/AqJ/0UUAk28nZ3d0t9fb2kpKRIS0uLTJgwQerq6iQ1NdXt0mLW3NzM+ViilJKWlhbJzMyUpCQ7Mza96x2JfD70bnwl8t91XyTy+UTTu2dYqsmxpKQkGT9+vIiIBAIBERFJTU1NuD/kWHA+doRCIavvR+96T6KeD70bf5yPHU57N+F+7QIAAPyN4QMAAFiV0MNHMBiU5cuXSzAYdLuUuOB8Bg6//dlwPgOH3/5sOJ/ElHALTgEAgL8l9JUPAADgPwwfAADAKoYPAABgFcMHAACwKmGHj5KSEpk4caIMGTJE8vLy5P3333e7JMd27NghM2bMkMzMTAkEAvLqq6/2+L5SSpYtWybjxo2ToUOHSkFBgXz00UfuFHsaxcXFMmXKFElJSZGxY8fKrFmzpLa2tsc+bW1tUlhYKKNHj5YRI0bInDlzpLGx0aWKE4NX+5fepXfp3cTg9/5NyOFj48aNsnjxYlm+fLns3r1bcnJyZPr06XL06FG3S3OktbVVcnJypKSkxPj9lStXyurVq2Xt2rWyc+dOGT58uEyfPl3a2tosV3p6lZWVUlhYKNXV1fLGG29IZ2enXHPNNdLa2hrZZ9GiRbJlyxYpKyuTyspKqa+vl9mzZ7tYtbu83L/0Lr1L7yYG3/evSkC5ubmqsLAw8nVXV5fKzMxUxcXFLlbVNyKiysvLI193d3erjIwM9fjjj0eypqYmFQwG1csvv+xChdE5evSoEhFVWVmplDpV++DBg1VZWVlkn9///vdKRFRVVZVbZbrKL/1L7w489G7i8lv/JtyVj46ODqmpqZGCgoJIlpSUJAUFBVJVVeViZfFx8OBBaWho6HF+oVBI8vLyPHF+4XBYRERGjRolIiI1NTXS2dnZ43zOO+88ycrK8sT5xJuf+5fe9Td6N7H5rX8Tbvg4duyYdHV1SXp6eo88PT1dGhoaXKoqfr48By+eX3d3tyxcuFCmTp0qF110kYicOp/k5GRJS0vrsa8Xzqc/+Ll/6V1/o3cTlx/7N+E+1RaJq7CwUPbu3SvvvPOO26UAUaF34WV+7N+Eu/IxZswYGTRokLZit7GxUTIyMlyqKn6+PAevnV9RUZFs3bpVtm/fHvnobZFT59PR0SFNTU099k/08+kvfu5fetff6N3E5Nf+TbjhIzk5WSZPniwVFRWRrLu7WyoqKiQ/P9/FyuIjOztbMjIyepxfc3Oz7Ny5MyHPTyklRUVFUl5eLm+++aZkZ2f3+P7kyZNl8ODBPc6ntrZWDh06lJDn09/83L/0rr/Ru4nF9/3r8oJXow0bNqhgMKhKS0vVvn371Ny5c1VaWppqaGhwuzRHWlpa1J49e9SePXuUiKinnnpK7dmzR33yySdKKaUeffRRlZaWpjZv3qw++OADNXPmTJWdna1OnDjhcuW6efPmqVAopN566y115MiRyHb8+PHIPnfffbfKyspSb775ptq1a5fKz89X+fn5LlbtLi/3L71L79K7icHv/ZuQw4dSSq1Zs0ZlZWWp5ORklZubq6qrq90uybHt27crEdG22267TSl16ravhx9+WKWnp6tgMKiuuuoqVVtb627RvTCdh4ioF198MbLPiRMn1D333KNGjhyphg0bpm666SZ15MgR94pOAF7tX3qX3qV3E4Pf+zeglFL9e20FAADgzxJuzQcAAPA3hg8AAGAVwwcAALCK4QMAAFjF8AEAAKxi+AAAAFYxfAAAAKsYPgAAgFUMHwAAwCqGDwAAYBXDBwAAsIrhAwAAWPX/r79ci3KPufUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.l1=nn.Linear(input_size,hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.l2=nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.l1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.l2(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "\n",
        "\n",
        "#loss and optimizer\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "#training loop\n",
        "n_total_steps=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    #100, 1, 28 ,28\n",
        "    #100, 784\n",
        "    images= images.reshape(-1,28*28).to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    #forward\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    #backwards\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    if(i+1)% 100 ==0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs},step {i+1}/{n_total_steps},loss={loss.item():.4f}')\n",
        "\n",
        "#test\n",
        "with torch.no_grad():\n",
        "  n_correct=0\n",
        "  n_samples=0\n",
        "  for images,labels in test_loader:\n",
        "    images=images.reshape(-1,28*28).to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs=model(images)\n",
        "\n",
        "    _,predictions=torch.max(outputs,1)\n",
        "    n_samples+=labels.shape[0]\n",
        "    n_correct+=(predictions==labels).sum().item()\n",
        "\n",
        "  acc=100.0*n_correct/n_samples\n",
        "  print(f'accuracy={acc}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwjESjFcwRR2",
        "outputId": "d23bd4ff-6dc3-4772-d785-48a67dd01a5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2,step 100/600,loss=0.5696\n",
            "epoch 1/2,step 200/600,loss=0.5328\n",
            "epoch 1/2,step 300/600,loss=0.3206\n",
            "epoch 1/2,step 400/600,loss=0.2718\n",
            "epoch 1/2,step 500/600,loss=0.2011\n",
            "epoch 1/2,step 600/600,loss=0.2754\n",
            "epoch 2/2,step 100/600,loss=0.1857\n",
            "epoch 2/2,step 200/600,loss=0.2318\n",
            "epoch 2/2,step 300/600,loss=0.2564\n",
            "epoch 2/2,step 400/600,loss=0.0818\n",
            "epoch 2/2,step 500/600,loss=0.2274\n",
            "epoch 2/2,step 600/600,loss=0.1473\n",
            "accuracy=95.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4G5jsVAv8mQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VqY7TWQZ1gHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}