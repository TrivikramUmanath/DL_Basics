{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#First tut"
      ],
      "metadata": {
        "id": "JBW0PfZInM1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "vluEH8VO1UEd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.empty(2,3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f60XUL7N1eL-",
        "outputId": "e26f7fd5-3a14-48e0-face-0f1269be6adc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.0595e-17,  4.4736e-41, -3.0596e-17],\n",
              "        [ 4.4736e-41, -3.0684e-17,  4.4736e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UbJH64W4ohF",
        "outputId": "84a5be2a-283e-4555-bada-516a87dcd42e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5994, 0.0820],\n",
            "        [0.2763, 0.3542]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.zeros(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW1DrB7B4o9_",
        "outputId": "bb1082f4-ff47-4780-d233-55964fb1adac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(2,2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7aRD8nDhsTS",
        "outputId": "3e3c0101-4656-4201-d783-fa9af7fa8326"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(2,2,dtype=torch.float16)\n",
        "print(x.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58WBu8Oyhta5",
        "outputId": "337a6bc5-43a2-4842-ccff-3b978ac763a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([2.5,0.1])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1axu6Z9hzYd",
        "outputId": "5e666623-1983-4547-e207-3d1cf726646b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(2,2)\n",
        "y=torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)\n",
        "z=x*y\n",
        "z=torch.add(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7iyknJah44Y",
        "outputId": "a6e0eab1-6e24-456c-f742-07820e4949e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4064, 0.3744],\n",
            "        [0.0338, 0.4242]])\n",
            "tensor([[0.9030, 0.7314],\n",
            "        [0.2148, 0.5032]])\n",
            "tensor([[1.3094, 1.1057],\n",
            "        [0.2486, 0.9274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.add_(x)\n",
        "print(y)#inplace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRqPzfFtiBhN",
        "outputId": "435391bf-a3bb-4a42-fada-1365efcaa8df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3094, 1.1057],\n",
            "        [0.2486, 0.9274]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=x-y\n",
        "z=torch.sub(x,y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YazbUU9tiIW4",
        "outputId": "947b2957-6b43-4cc6-eb80-dcb737af15e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9030, -0.7314],\n",
            "        [-0.2148, -0.5032]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=x-y\n",
        "z=torch.mul(x,y)#elementwise multiplication\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MusyYyJ7iSBg",
        "outputId": "de2d2ccd-34d2-4f78-c6bb-d53b4efd2937"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5322, 0.4140],\n",
            "        [0.0084, 0.3934]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=torch.div(x,y)#elementwise\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUI-6dwkidl9",
        "outputId": "96a230eb-6f08-48c0-9199-117441d8dc66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3104, 0.3386],\n",
            "        [0.1359, 0.4574]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:,0])\n",
        "print(x[1,1])\n",
        "print(x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zkrDsH2igJF",
        "outputId": "0075c816-2073-4cae-cb95-ba9f9556b1ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8937, 0.8367, 0.5882],\n",
            "        [0.1751, 0.4855, 0.2875],\n",
            "        [0.5273, 0.1506, 0.6809],\n",
            "        [0.6013, 0.7376, 0.5326],\n",
            "        [0.6135, 0.0779, 0.3270]])\n",
            "tensor([0.8937, 0.1751, 0.5273, 0.6013, 0.6135])\n",
            "tensor(0.4855)\n",
            "0.48547083139419556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.rand(4,4)\n",
        "print(x)\n",
        "y=x.view(16)\n",
        "print(y)\n",
        "y=x.view(-1,8)#-1 automatic\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrfhpEmWi5mn",
        "outputId": "88915751-a56c-40e8-e793-21602837a908"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0116, 0.2980, 0.4711, 0.3724],\n",
            "        [0.7760, 0.7229, 0.7473, 0.7523],\n",
            "        [0.4717, 0.1165, 0.1535, 0.8783],\n",
            "        [0.0966, 0.1323, 0.8184, 0.9492]])\n",
            "tensor([0.0116, 0.2980, 0.4711, 0.3724, 0.7760, 0.7229, 0.7473, 0.7523, 0.4717,\n",
            "        0.1165, 0.1535, 0.8783, 0.0966, 0.1323, 0.8184, 0.9492])\n",
            "tensor([[0.0116, 0.2980, 0.4711, 0.3724, 0.7760, 0.7229, 0.7473, 0.7523],\n",
            "        [0.4717, 0.1165, 0.1535, 0.8783, 0.0966, 0.1323, 0.8184, 0.9492]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "pl21MXd5jO0Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.ones(5)\n",
        "print(a)\n",
        "b=a.numpy()\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h01CRtYVjaZK",
        "outputId": "df99e852-beba-4173-9a48-8f7c0f02dbbd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL3mP9gdjf_M",
        "outputId": "614b54b7-c7d1-47bb-ff8e-7700e9966ec6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=np.ones(5)\n",
        "print(a)\n",
        "b=torch.from_numpy(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTMrxRLUjnnw",
        "outputId": "76e2e181-45c8-47db-bec9-f418d822d820"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a+=1\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c8XR_Mjv3b",
        "outputId": "cec93884-1900-48d3-8ea4-e699ddd091c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(\"cuda\")\n",
        "  x=torch.ones(5,device=device)\n",
        "  y=torch.ones(5)\n",
        "  y=y.to(device)\n",
        "  z=x+y\n",
        "  # print(z)\n",
        "  z=z.to(\"cpu\")\n",
        "  print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqEMgoZXj4oa",
        "outputId": "7145078e-4eec-4f3b-dd2c-5b415665164d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7VFJLg9kFpl",
        "outputId": "d633b493-76e2-4b61-f1e6-4b466d9ea571"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.ones(5,requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgCzW5BekYyE",
        "outputId": "1c553663-19c6-4206-f05f-819d0c62efa5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Tut"
      ],
      "metadata": {
        "id": "tby6AhBBnRCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.randn(3,requires_grad=True)\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVLHNgBQk2t-",
        "outputId": "ef9080f8-3e98-494b-df3c-210baf92e4fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1933,  0.2070,  0.2451], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x+2\n",
        "print(y)\n",
        "z=y*y*2\n",
        "print(z)\n",
        "z=z.mean()\n",
        "print(z)\n",
        "z.backward() #dz/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtG2Gp_8na1q",
        "outputId": "cb61dc2c-c9ca-4719-a3e4-1e1ea011af0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8067, 2.2070, 2.2451], grad_fn=<AddBackward0>)\n",
            "tensor([ 6.5284,  9.7418, 10.0812], grad_fn=<MulBackward0>)\n",
            "tensor(8.7838, grad_fn=<MeanBackward0>)\n",
            "tensor([ 7.9495, 17.6561,  9.0703])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=y*y*2\n",
        "v=torch.tensor([0.1,1.0,0.01],dtype=torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZK5vsyQpprp",
        "outputId": "80ee0903-2d88-4b5b-ef69-0568c928e5ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.6722, 26.4842,  9.1601])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_T6-cpfngfC",
        "outputId": "30270554-6477-46d3-9c42-5f47f3ed757e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1933,  0.2070,  0.2451])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhYedCo4qUX6",
        "outputId": "46d3a19e-9eaa-448a-d102-011a1379db4b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1933,  0.2070,  0.2451])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y=x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IExx1OlrsYb",
        "outputId": "20cbe0b1-9184-425c-fb97-8fb570271d4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8067, 2.2070, 2.2451])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights=torch.ones(4,requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output=(weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  # weights.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzpt8Z5ur0Bd",
        "outputId": "9e94054d-9f78-4f6b-fa28-938833b2d579"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9oqmkV_4yOi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation Theory"
      ],
      "metadata": {
        "id": "grBKb8vryTPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.tensor(1.0)\n",
        "y=torch.tensor(2.0)\n",
        "\n",
        "w=torch.tensor(1.0,requires_grad=True)\n",
        "\n",
        "y_hat=w*x\n",
        "loss=(y_hat-y)**2\n",
        "print(loss)\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "#backward pass above\n",
        "#update weights\n",
        "#next forward and backward pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmowH2j8scxU",
        "outputId": "30da1101-f302-42be-f246-0c6e499711a7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradientg Descent with AutoGrad and Bakckprop"
      ],
      "metadata": {
        "id": "VUVNP4ss2PWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=np.array([1,2,3,4],dtype=np.float32)\n",
        "Y=np.array([2,4,6,8],dtype=np.float32)\n",
        "\n",
        "w=0.0\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  dw=gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w-=learning_rate*dw\n",
        "  if epoch%2 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkbXdwlQ30bR",
        "outputId": "300dbe11-84dd-4e86-e422-75648d8e000a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:0.0\n",
            "epoch 1: w=1.200, loss=30.00000000\n",
            "epoch 3: w=1.872, loss=0.76800019\n",
            "epoch 5: w=1.980, loss=0.01966083\n",
            "epoch 7: w=1.997, loss=0.00050332\n",
            "epoch 9: w=1.999, loss=0.00001288\n",
            "Predictions after training:9.998952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-=learning_rate*w.grad\n",
        "  w.grad.zero_()\n",
        "  if epoch%10 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqNxSMHW5UVu",
        "outputId": "455c0dcf-4224-463b-e049-c76f899b0b9e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:tensor(0., grad_fn=<MulBackward0>)\n",
            "epoch 1: w=0.300, loss=30.00000000\n",
            "epoch 11: w=1.665, loss=1.16278565\n",
            "epoch 21: w=1.934, loss=0.04506890\n",
            "epoch 31: w=1.987, loss=0.00174685\n",
            "epoch 41: w=1.997, loss=0.00006770\n",
            "epoch 51: w=1.999, loss=0.00000262\n",
            "epoch 61: w=2.000, loss=0.00000010\n",
            "epoch 71: w=2.000, loss=0.00000000\n",
            "epoch 81: w=2.000, loss=0.00000000\n",
            "epoch 91: w=2.000, loss=0.00000000\n",
            "Predictions after training:tensor(10.0000, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Loss and Optimizer"
      ],
      "metadata": {
        "id": "tDyj1TFX6g_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss - MSE\n",
        "\n",
        "\n",
        "\n",
        "# gradient\n",
        "#MSE =1/N *(w*x-y)**2\n",
        "#dj/dx=1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x,y_predicted-y).mean()\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(forward(5)))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD([w],lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(forward(5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhjgZqXy57gB",
        "outputId": "1180e1df-b9a9-4a49-abf9-9cb4879b06a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions before training:tensor(0., grad_fn=<MulBackward0>)\n",
            "epoch 1: w=0.300, loss=30.00000000\n",
            "epoch 11: w=1.665, loss=1.16278565\n",
            "epoch 21: w=1.934, loss=0.04506890\n",
            "epoch 31: w=1.987, loss=0.00174685\n",
            "epoch 41: w=1.997, loss=0.00006770\n",
            "epoch 51: w=1.999, loss=0.00000262\n",
            "epoch 61: w=2.000, loss=0.00000010\n",
            "epoch 71: w=2.000, loss=0.00000000\n",
            "epoch 81: w=2.000, loss=0.00000000\n",
            "epoch 91: w=2.000, loss=0.00000000\n",
            "Predictions after training:tensor(10.0000, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "X_test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "print(n_samples,n_features)\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "#model=nn.Linear(input_size,output_size)\n",
        "model=nn.Linear(input_size,output_size)\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(model(X_test).item()))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=model(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(model(X_test).item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Mqzkkf74Vi",
        "outputId": "47aa8db1-bf4c-47ee-db35-31ac23261352"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Predictions before training:4.347386360168457\n",
            "epoch 1: w=0.837, loss=7.76073170\n",
            "epoch 11: w=1.477, loss=0.43018377\n",
            "epoch 21: w=1.590, loss=0.22717299\n",
            "epoch 31: w=1.617, loss=0.20934579\n",
            "epoch 41: w=1.631, loss=0.19704153\n",
            "epoch 51: w=1.642, loss=0.18556964\n",
            "epoch 61: w=1.653, loss=0.17476842\n",
            "epoch 71: w=1.663, loss=0.16459602\n",
            "epoch 81: w=1.673, loss=0.15501556\n",
            "epoch 91: w=1.683, loss=0.14599292\n",
            "Predictions after training:9.364309310913086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design model,input and output size ,forward pass\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training oss\n",
        "# - forwards pass: compute Prediction\n",
        "# - backward pass: gradients\n",
        "# - update weights\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#f=w*x\n",
        "#f=2*x\n",
        "\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "X_test=torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "print(n_samples,n_features)\n",
        "input_size=n_features\n",
        "output_size=n_features\n",
        "\n",
        "#model=nn.Linear(input_size,output_size)\n",
        "# model=nn.Linear(input_size,output_size)\n",
        "\n",
        "\n",
        "# 1 Design model, input and output size, forward pass\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim):  # Corrected: __init__ not _init_\n",
        "    super(LinearRegression, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "\n",
        "print(\"Predictions before training:\" +str(model(X_test).item()))\n",
        "\n",
        "#Training\n",
        "learning_rate=0.01\n",
        "n_iters=100\n",
        "\n",
        "losee=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #predictions=forward pass\n",
        "  y_pred=model(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={l:.8f}')\n",
        "\n",
        "print(\"Predictions after training:\" +str(model(X_test).item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POlq_SYB9v45",
        "outputId": "aef5051c-89f0-43a7-a2e9-8a4aa97e1242"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Predictions before training:3.870293140411377\n",
            "epoch 1: w=0.986, loss=11.59272003\n",
            "epoch 11: w=1.768, loss=0.30952698\n",
            "epoch 21: w=1.896, loss=0.01704516\n",
            "epoch 31: w=1.919, loss=0.00895203\n",
            "epoch 41: w=1.924, loss=0.00824726\n",
            "epoch 51: w=1.927, loss=0.00776249\n",
            "epoch 61: w=1.929, loss=0.00731054\n",
            "epoch 71: w=1.931, loss=0.00688503\n",
            "epoch 81: w=1.933, loss=0.00648428\n",
            "epoch 91: w=1.935, loss=0.00610685\n",
            "Predictions after training:9.869986534118652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression using Pytorch"
      ],
      "metadata": {
        "id": "zDYBi3UyASjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design (input size,output size,forward pass)\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training Loop\n",
        "    # -forward pass: compute predictions and loss\n",
        "    # -backward pass: gradients\n",
        "    # -update weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_numpy,y_numpy = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
        "X=torch.from_numpy(x_numpy.astype(np.float32))\n",
        "Y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "Y=Y.view(Y.shape[0],1)\n",
        "n_samples,n_features=X.shape\n",
        "#Model\n",
        "input_size=n_features\n",
        "output_size=1\n",
        "model=nn.Linear(input_size,output_size)\n",
        "criteria=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "#Training\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted=model(X)\n",
        "  loss=criteria(y_predicted,Y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w={w[0][0].item():.3f}, loss={loss:.4f}')\n",
        "\n",
        " #plot\n",
        "predicted=model(X).detach().numpy()\n",
        "plt.plot(x_numpy,y_numpy,'ro')\n",
        "plt.plot(x_numpy,predicted,'b')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "kcpviQsD-9Ut",
        "outputId": "3a06d11f-08be-4485-baa0-a411193e386d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w=1.561, loss=5704.9985\n",
            "epoch 11: w=13.467, loss=4226.7202\n",
            "epoch 21: w=23.612, loss=3157.8440\n",
            "epoch 31: w=32.257, loss=2384.1265\n",
            "epoch 41: w=39.626, loss=1823.4814\n",
            "epoch 51: w=45.909, loss=1416.8419\n",
            "epoch 61: w=51.266, loss=1121.6422\n",
            "epoch 71: w=55.835, loss=907.1669\n",
            "epoch 81: w=59.732, loss=751.2246\n",
            "epoch 91: w=63.057, loss=637.7620\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression using Pytorch"
      ],
      "metadata": {
        "id": "NeoPElSNDVlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Design (input size,output size,forward pass)\n",
        "#2 Construct loss and optimizer\n",
        "#3 Training Loop\n",
        "    # -forward pass: compute predictions and loss\n",
        "    # -backward pass: gradients\n",
        "    # -update weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bc=datasets.load_breast_cancer()\n",
        "X,y=bc.data,bc.target\n",
        "\n",
        "n_samples,n_features=X.shape\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1234)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n",
        "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
        "y_train=y_train.view(y_train.shape[0],1)\n",
        "y_test=y_test.view(y_test.shape[0],1)\n",
        "\n",
        "#f=wx+b,sigmoid at the end\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_input_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear=nn.Linear(n_input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted=torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "#Model\n",
        "model=LogisticRegression(n_features)\n",
        "#Loss and Optimizer\n",
        "criteria=nn.BCELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "\n",
        "#Training\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted=model(X_train)\n",
        "  loss=criteria(y_predicted,y_train)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: loss={loss:.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted=model(X_test)\n",
        "  y_predicted_cls=y_predicted.round()\n",
        "  acc=y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy={acc:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npa8pXioC-1M",
        "outputId": "08131186-68e3-4ffd-d01b-28143305202a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: loss=0.4731\n",
            "epoch 20: loss=0.4075\n",
            "epoch 30: loss=0.3618\n",
            "epoch 40: loss=0.3282\n",
            "epoch 50: loss=0.3022\n",
            "epoch 60: loss=0.2815\n",
            "epoch 70: loss=0.2646\n",
            "epoch 80: loss=0.2504\n",
            "epoch 90: loss=0.2383\n",
            "epoch 100: loss=0.2278\n",
            "accuracy=0.9211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset and DataLoader"
      ],
      "metadata": {
        "id": "n4E5gx46HX3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "epoch = 1 forward and backward pass of ALL training samples\n",
        "batch_size= number of training sample in one forward and backward pass\n",
        "number of iterations = number of passes,each pass using[batch_size] number of samples\n",
        "e.g 100 samples,batch_size=20 -->100/20=5 iterations for 1 epoch\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy= np.loadtxt('/content/WineQT.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x=torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]])\n",
        "    self.n_samples=xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "dataset = WineDataset()\n",
        "# first_data = dataset[0]\n",
        "# features,labels = first_data\n",
        "# print(features,labels)\n",
        "\n",
        "dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "datatiter=iter(dataloader)\n",
        "data=next(datatiter)\n",
        "features,labels=data\n",
        "print(features,labels)\n",
        "\n",
        "\n",
        "#training loop\n",
        "num_epochs=2\n",
        "total_samples=len(dataset)\n",
        "n_iterations=math.ceil(total_samples/4)\n",
        "print(total_samples,n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(inputs,labels) in enumerate(dataloader):\n",
        "     # forward and backward,update (placeholders for actual model logic)\n",
        "\n",
        "     # --- ADDED CONDITION HERE TO MATCH VIDEO'S PRINT FREQUENCY ---\n",
        "     if (i + 1) % 5 == 0: # Print every 5th step\n",
        "       print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs shape: {inputs.shape}')\n",
        "\n",
        "print(\"\\nTraining loop simulation complete.\")\n",
        "\n",
        "# torchvision.datasets.MNIST()\n",
        "#fashion=mnist,tifar,coco\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmXfMt-zGc-I",
        "outputId": "56c9915d-3a48-4cea-ce26-8c95d0d168dc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.9000e-01, 1.4000e-01, 2.0000e+00, 8.4000e-02, 2.5000e+01, 4.8000e+01,\n",
            "         9.9810e-01, 3.1400e+00, 5.6000e-01, 9.7000e+00, 5.0000e+00, 6.6500e+02],\n",
            "        [5.3000e-01, 1.4000e-01, 2.1000e+00, 6.4000e-02, 1.5000e+01, 2.9000e+01,\n",
            "         9.9323e-01, 3.3500e+00, 6.1000e-01, 1.2100e+01, 6.0000e+00, 1.2970e+03],\n",
            "        [6.4000e-01, 9.0000e-02, 2.5000e+00, 8.1000e-02, 1.5000e+01, 2.6000e+01,\n",
            "         9.9538e-01, 3.5700e+00, 6.3000e-01, 1.2000e+01, 5.0000e+00, 1.5380e+03],\n",
            "        [4.7000e-01, 4.3000e-01, 2.1000e+00, 1.7100e-01, 2.7000e+01, 6.6000e+01,\n",
            "         9.9820e-01, 3.1700e+00, 7.6000e-01, 1.0800e+01, 6.0000e+00, 1.1090e+03]]) tensor([[ 9.4000],\n",
            "        [ 7.2000],\n",
            "        [ 6.2000],\n",
            "        [10.8000]])\n",
            "1143 286\n",
            "epoch 1/2, step 5/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 10/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 15/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 20/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 25/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 30/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 35/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 40/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 45/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 50/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 55/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 60/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 65/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 70/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 75/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 80/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 85/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 90/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 95/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 100/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 105/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 110/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 115/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 120/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 125/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 130/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 135/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 140/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 145/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 150/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 155/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 160/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 165/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 170/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 175/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 180/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 185/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 190/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 195/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 200/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 205/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 210/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 215/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 220/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 225/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 230/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 235/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 240/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 245/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 250/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 255/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 260/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 265/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 270/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 275/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 280/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 1/2, step 285/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 5/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 10/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 15/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 20/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 25/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 30/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 35/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 40/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 45/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 50/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 55/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 60/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 65/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 70/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 75/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 80/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 85/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 90/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 95/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 100/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 105/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 110/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 115/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 120/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 125/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 130/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 135/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 140/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 145/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 150/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 155/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 160/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 165/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 170/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 175/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 180/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 185/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 190/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 195/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 200/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 205/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 210/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 215/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 220/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 225/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 230/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 235/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 240/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 245/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 250/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 255/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 260/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 265/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 270/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 275/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 280/286, inputs shape: torch.Size([4, 12])\n",
            "epoch 2/2, step 285/286, inputs shape: torch.Size([4, 12])\n",
            "\n",
            "Training loop simulation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataSet Transforms"
      ],
      "metadata": {
        "id": "ZJh9PDJ3QyVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# dataset=torchvision.datasets.MNIST(\n",
        "#     root='./data',transform=torchvision.transforms.ToTensor()\n",
        "# )\n",
        "\n",
        "'''\n",
        "Transforms can be applied to PIL images,tensors,ndarrays or custom data\n",
        "during creation of the Dataset\n",
        "\n",
        "\n",
        "On Images:CeterCrop,Grayscale,Pad,RandomAffine,RandomCrop,RandomHorizontalFlip\n",
        ",RandomRotation,Resize,Scale\n",
        "\n",
        "On Tensors\n",
        "LinearTransformation,Normalize,RandomErasing\n",
        "\n",
        "Conversion\n",
        "TopIImage: from tensor or ndarray\n",
        "ToTensor: from numpy.ndarray or PILImage\n",
        "\n",
        "Generic\n",
        "Write own class\n",
        "\n",
        "Compose Multiple Transform\n",
        "composed=transform.Compose([Rescale[256],RandomCrop(224)])\n",
        "torchvision.transform.ReScale(256)\n",
        "torchvision.transform.ToTensor()\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "epoch = 1 forward and backward pass of ALL training samples\n",
        "batch_size= number of training sample in one forward and backward pass\n",
        "number of iterations = number of passes,each pass using[batch_size] number of samples\n",
        "e.g 100 samples,batch_size=20 -->100/20=5 iterations for 1 epoch\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self,transform=None):\n",
        "    #data loading\n",
        "    xy= np.loadtxt('/content/WineQT.csv',delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x=torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]])\n",
        "    self.n_samples=xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sample= self.x[index],self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample=self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self,sample):\n",
        "    inputs,targets=sample\n",
        "    return torch.from_numpy(inputs),torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self,factor):\n",
        "    self.factor=factor\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    inputs,targets=sample\n",
        "    inputs*=self.factor\n",
        "    return inputs,targets\n",
        "\n",
        "\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features,labels = first_data\n",
        "print(type(features),type(labels))\n",
        "\n",
        "composed=torchvision.transforms.Compose([ToTensor(),MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features,labels = first_data\n",
        "print(type(features),type(labels))\n",
        "\n",
        "#\n",
        "\n",
        "# dataloader=DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "# datatiter=iter(dataloader)\n",
        "# data=next(datatiter)\n",
        "# features,labels=data\n",
        "# print(features,labels)\n",
        "\n",
        "\n",
        "# #training loop\n",
        "# num_epochs=2\n",
        "# total_samples=len(dataset)\n",
        "# n_iterations=math.ceil(total_samples/4)\n",
        "# print(total_samples,n_iterations)\n",
        "# for epoch in range(num_epochs):\n",
        "#   for i,(inputs,labels) in enumerate(dataloader):\n",
        "#      # forward and backward,update (placeholders for actual model logic)\n",
        "\n",
        "#      # --- ADDED CONDITION HERE TO MATCH VIDEO'S PRINT FREQUENCY ---\n",
        "#      if (i + 1) % 5 == 0: # Print every 5th step\n",
        "#        print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs shape: {inputs.shape}')\n",
        "\n",
        "print(\"\\nTraining loop simulation complete.\")\n",
        "\n",
        "# torchvision.datasets.MNIST()\n",
        "#fashion=mnist,tifar,coco\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "rTcQZWAzLiOH",
        "outputId": "03c6319d-e79c-4483-bf49-90546ba9bb10"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'WineDataset' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-ba1fdb7ec85e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-ba1fdb7ec85e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m       \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'WineDataset' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    xy = np.loadtxt('/content/WineQT.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]]\n",
        "    self.n_samples = xy.shape[0]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    inputs = self.x[index]\n",
        "    targets = self.y[index]\n",
        "\n",
        "    sample = {'inputs': inputs, 'targets': targets}\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample['inputs'], sample['targets']\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample['inputs'], sample['targets']\n",
        "    return {'inputs': torch.from_numpy(inputs),\n",
        "            'targets': torch.from_numpy(targets)}\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    sample['inputs'] = sample['inputs'] * self.factor\n",
        "    return sample\n",
        "\n",
        "dataset_with_to_tensor = WineDataset(transform=ToTensor())\n",
        "first_data_to_tensor = dataset_with_to_tensor[0]\n",
        "features_to_tensor, labels_to_tensor = first_data_to_tensor\n",
        "print(f\"Features type after ToTensor: {type(features_to_tensor)}\")\n",
        "print(f\"Labels type after ToTensor: {type(labels_to_tensor)}\")\n",
        "print(f\"Features value (first sample):\\n{features_to_tensor}\")\n",
        "print(f\"Labels value (first sample):\\n{labels_to_tensor}\")\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset_with_composed = WineDataset(transform=composed)\n",
        "first_data_composed = dataset_with_composed[0]\n",
        "features_composed, labels_composed = first_data_composed\n",
        "print(f\"\\nFeatures type after Composed: {type(features_composed)}\")\n",
        "print(f\"Labels type after Composed: {type(labels_composed)}\")\n",
        "print(f\"Features value (first sample, multiplied by 4):\\n{features_composed}\")\n",
        "print(f\"Labels value (first sample, unchanged):\\n{labels_composed}\")\n",
        "\n",
        "print(\"\\nTraining loop simulation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZRdiYWlXNqT",
        "outputId": "b26f5330-f1c2-4023-bf9b-e2e3b506d98d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features type after ToTensor: <class 'torch.Tensor'>\n",
            "Labels type after ToTensor: <class 'torch.Tensor'>\n",
            "Features value (first sample):\n",
            "tensor([ 0.7000,  0.0000,  1.9000,  0.0760, 11.0000, 34.0000,  0.9978,  3.5100,\n",
            "         0.5600,  9.4000,  5.0000,  0.0000])\n",
            "Labels value (first sample):\n",
            "tensor([7.4000])\n",
            "\n",
            "Features type after Composed: <class 'torch.Tensor'>\n",
            "Labels type after Composed: <class 'torch.Tensor'>\n",
            "Features value (first sample, multiplied by 4):\n",
            "tensor([  2.8000,   0.0000,   7.6000,   0.3040,  44.0000, 136.0000,   3.9912,\n",
            "         14.0400,   2.2400,  37.6000,  20.0000,   0.0000])\n",
            "Labels value (first sample, unchanged):\n",
            "tensor([7.4000])\n",
            "\n",
            "Training loop simulation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax and Cross - Entropy"
      ],
      "metadata": {
        "id": "D37kLxNtYNgU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rb87oBEaXm2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
